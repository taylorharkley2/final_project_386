{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "724d6b17",
   "metadata": {},
   "source": [
    "From the old lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a21e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''Passes a request for weather from a certain location to an LLM.\n",
    "The LLM produces valid JSON that could be ingested to create an https post request.\n",
    "\n",
    "Modified from https://ollama.com/blog/structured-outputs\n",
    "'''\n",
    "from ollama import chat\n",
    "import sys\n",
    "\n",
    "\n",
    "prompt = sys.argv[1] # first argument after user_creation.py\n",
    "\n",
    "response = chat( # from terminal to the LLM \"prompt\" variable\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': \n",
    "      prompt\n",
    "    ,\n",
    "    },\n",
    "    {\n",
    "      'role': 'system',\n",
    "      'content': '''\n",
    "        Return your answer in one of four formats. The first format will be reformatting the city name provided to replace spaces with a +. If the user says something\n",
    "        like: do you want \n",
    "        \n",
    "        The second format will be to take \n",
    "        the name of a landmark, put a tilda in front of it and then replace spaces with + in this case you would receive Los Angeles and return . The third format will be if the user asks for the weather and provides a three letter airport \n",
    "        identifier code, in this case, you should return http://wttr.in/abc, where abc is the three letter code.\n",
    "      ''',\n",
    "    }\n",
    "  ],\n",
    "  model='gemma:2b',\n",
    ")\n",
    "\n",
    "#pets = User.model_validate_json(response.message.content)\n",
    "#print(pets)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This script evaluates an LLM prompt for processing text so that it can be used for the wttr.in API\"\"\"\n",
    "\n",
    "from ollama import Client\n",
    "\n",
    "LLM_MODEL: str = \"gemma3:27b\"    # Optional, change this to be the model you want\n",
    "client: Client = Client(\n",
    "  host='http:/ai.dfec.xyz:11434' # Optional, change this to be the URL of your LLM\n",
    ")\n",
    "\n",
    "\n",
    "# TODO: define  llm_parse_for_wttr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5a9038",
   "metadata": {},
   "source": [
    "DICTIONARY OF TEST CASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9666bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Test cases\n",
    "test_cases = [ # TODO: Replace these test cases with ones for wttr.in\n",
    "    {\n",
    "        \"input\": \"What is the weather in Los Angeles\",\n",
    "        \"expected\": \"Los+Angeles\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What color is the weather in the Eiffel Tower\",\n",
    "        \"expected\": \"~Eiffel+Tower\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What is the weather in DFW?\",\n",
    "        \"expected\": '{\"name\": \"Alice\", \"age\": 30}'\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"I love Vietnamese food\",\n",
    "        \"expected\": '{\"name\": \"Alice\", \"age\": 30}'\n",
    "    },\n",
    "]\n",
    "\n",
    "# Function to iterate through test cases\n",
    "def run_tests():\n",
    "    num_passed = 0\n",
    "\n",
    "    for i, test in enumerate(test_cases, 1):\n",
    "        raw_input = test[\"input\"]\n",
    "        expected_output = test[\"expected\"]\n",
    "\n",
    "        print(f\"\\nTest {i}: {raw_input}\")\n",
    "        try:\n",
    "            result = llm_parse_for_wttr(raw_input).strip()\n",
    "            expected = expected_output.strip()\n",
    "\n",
    "            print(\"LLM Output  :\", result)\n",
    "            print(\"Expected    :\", expected)\n",
    "\n",
    "            if result == expected:\n",
    "                print(\"‚úÖ PASS\")\n",
    "                num_passed += 1\n",
    "            else:\n",
    "                print(\"‚ùå FAIL\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"üí• ERROR:\", e)\n",
    "\n",
    "    print(f\"\\nSummary: {num_passed} / {len(test)} tests passed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359fb6df",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233aaf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the test cases\n",
    "run_tests()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
