{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "724d6b17",
   "metadata": {},
   "source": [
    "Parse Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4455904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Using cached ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpx<0.29,>=0.27 (from ollama)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3.0.0,>=2.9.0 (from ollama)\n",
      "  Using cached pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting anyio (from httpx<0.29,>=0.27->ollama)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi (from httpx<0.29,>=0.27->ollama)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<0.29,>=0.27->ollama)\n",
      "  Using cached httpcore-1.0.8-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<0.29,>=0.27->ollama)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.29,>=0.27->ollama)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Using cached pydantic_core-2.33.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.13.2)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.2.2)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<0.29,>=0.27->ollama)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached ollama-0.4.7-py3-none-any.whl (13 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.8-py3-none-any.whl (78 kB)\n",
      "Using cached pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Using cached pydantic_core-2.33.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.9 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: typing-inspection, sniffio, pydantic-core, idna, h11, certifi, annotated-types, pydantic, httpcore, anyio, httpx, ollama\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 certifi-2025.1.31 h11-0.14.0 httpcore-1.0.8 httpx-0.28.1 idna-3.10 ollama-0.4.7 pydantic-2.11.3 pydantic-core-2.33.1 sniffio-1.3.1 typing-inspection-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1a3b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This script evaluates an LLM prompt for processing text so that it can be used for the wttr.in API\"\"\"\n",
    "import sys\n",
    "from ollama import Client\n",
    "\n",
    "LLM_MODEL: str = \"gemma3:27b\"    # Optional, change this to be the model you want\n",
    "client: Client = Client(\n",
    "  host='http:/ai.dfec.xyz:11434' # Optional, change this to be the URL of your LLM\n",
    ")\n",
    "\n",
    "\n",
    "# TODO: define  llm_parse_for_wttr()\n",
    "\n",
    "def llm_parse_for_wttr(prompt):\n",
    "\n",
    "  prompt = sys.argv[1] # first argument after filename.py\n",
    "\n",
    "\n",
    "  response = chat( # from terminal to the LLM \"prompt\" variable\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': \n",
    "      prompt\n",
    "    ,\n",
    "    },\n",
    "    {\n",
    "      'role': 'system',\n",
    "      'content': '''\n",
    "        Return your answer in one of four formats. The first format will be to reformatting the city name provided to replace spaces with a +. If the user says something\n",
    "        like: Can I get the weather from Los angeles?\n",
    "\n",
    "        you would return Los+Angeles\n",
    "        \n",
    "        The second format will be if the user provides a landmark instead of a city name.\n",
    "\n",
    "        you would return the name of a landmark with a tilda in front of it and then replace spaces with + in this case you would receive Los Angeles and return \n",
    "        something like ~Eiffel+Tower\n",
    "\n",
    "        . The third format will be if the user asks for the weather and provides a three letter airport \n",
    "        identifier code, in this case, you should return http://wttr.in/abc, where abc is the three letter code.\n",
    "      ''',\n",
    "    }\n",
    "  ],\n",
    "   #model='gemma3:27b',\n",
    ")\n",
    "\n",
    "\n",
    "  return response\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5a9038",
   "metadata": {},
   "source": [
    "DICTIONARY OF TEST CASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9666bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Test cases\n",
    "test_cases = [ # TODO: Replace these test cases with ones for wttr.in\n",
    "    {\n",
    "        \"input\": \"What is the weather in Los Angeles\",\n",
    "        \"expected\": \"Los+Angeles\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What color is the weather in the Eiffel Tower\",\n",
    "        \"expected\": \"~Eiffel+Tower\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What is the weather in DFW?\",\n",
    "        \"expected\": '{\"name\": \"Alice\", \"age\": 30}'\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"I love Vietnamese food\",\n",
    "        \"expected\": '{\"name\": \"Alice\", \"age\": 30}'\n",
    "    },\n",
    "]\n",
    "\n",
    "# Function to iterate through test cases\n",
    "def run_tests():\n",
    "    num_passed = 0\n",
    "\n",
    "    for i, test in enumerate(test_cases, 1):\n",
    "        raw_input = test[\"input\"]\n",
    "        expected_output = test[\"expected\"]\n",
    "\n",
    "        print(f\"\\nTest {i}: {raw_input}\")\n",
    "        try:\n",
    "            result = llm_parse_for_wttr(raw_input).strip()\n",
    "            expected = expected_output.strip()\n",
    "\n",
    "            print(\"LLM Output  :\", result)\n",
    "            print(\"Expected    :\", expected)\n",
    "\n",
    "            if result == expected:\n",
    "                print(\"‚úÖ PASS\")\n",
    "                num_passed += 1\n",
    "            else:\n",
    "                print(\"‚ùå FAIL\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"üí• ERROR:\", e)\n",
    "\n",
    "    print(f\"\\nSummary: {num_passed} / {len(test)} tests passed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359fb6df",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "233aaf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 1: What is the weather in Los Angeles\n",
      "üí• ERROR: name 'chat' is not defined\n",
      "\n",
      "Test 2: What color is the weather in the Eiffel Tower\n",
      "üí• ERROR: name 'chat' is not defined\n",
      "\n",
      "Test 3: What is the weather in DFW?\n",
      "üí• ERROR: name 'chat' is not defined\n",
      "\n",
      "Test 4: I love Vietnamese food\n",
      "üí• ERROR: name 'chat' is not defined\n",
      "\n",
      "Summary: 0 / 2 tests passed.\n"
     ]
    }
   ],
   "source": [
    "# Run the test cases\n",
    "run_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
